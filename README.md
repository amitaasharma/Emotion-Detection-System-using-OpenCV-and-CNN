# Emotion-Detection-System-using-OpenCV-and-CNN
Machine Learning project on Emotion Detection System
ğŸ¯ Human Emotion and Gesture Recognition System

Developed by Amita Sharma

A deep learningâ€“powered project integrating Facial Emotion Recognition and Finger Count Detection using TensorFlow, Keras, and OpenCV.
This system enables computers to understand human emotions from facial expressions and count fingers using real-time video input â€” bridging human-computer interaction through vision-based AI.


ğŸ“˜ Overview

This repository combines two intelligent computer vision modules:

Emotion Recognition:
Detects human faces and classifies their emotional state (e.g., Happy, Sad, Angry, Fearful, Neutral, Disgust, Surprise) using a CNN trained on the FER-2013 dataset.

Finger Count Detection:
Utilizes contour and convex hull analysis to count the number of fingers shown to the webcam in real time.

Together, these modules demonstrate the potential of AI in emotion-aware systems, gesture-based interfaces, and assistive technologies.


ğŸ§  Project Architecture
Emotion Recognition

Dataset: FER-2013

Model: Convolutional Neural Network (CNN)

Input Size: 48Ã—48 grayscale images

Framework: TensorFlow/Keras

Classes: 7 Emotion Categories

Training: 10 epochs with data augmentation

Optimizer: Adam

Loss Function: Categorical Cross-Entropy

Finger Count Detection

Libraries Used: OpenCV, NumPy

Technique:

ROI (Region of Interest) extraction

Skin color thresholding (HSV filtering)

Contour and Convex Hull detection

Convexity defects analysis to count raised fingers

âš™ Tech Stack
Component	Technology
Language	Python 3
Deep Learning	TensorFlow, Keras
Computer Vision	OpenCV
Data Handling	NumPy
Visualization	Matplotlib
Dataset	FER-2013

ğŸ“‚ Repository Structure
ğŸ“¦ Human-Emotion-and-Gesture-Recognition
â”‚
â”œâ”€â”€ Emotion_Recognition.ipynb       # CNN-based emotion detection
â”œâ”€â”€ Fingercount.ipynb               # Finger count detection module
â”œâ”€â”€ fer2013/                        # Dataset directory (train/test split)
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â””â”€â”€ README.md


ğŸ§© Features

âœ… Real-time face detection and emotion classification
âœ… Finger count detection using webcam feed
âœ… Lightweight and modular architecture
âœ… Compatible with standard webcams
âœ… Eager execution and debugging support
âœ… Automatically saves and loads trained models


ğŸš€ How to Run
1ï¸âƒ£ Clone the Repository

2ï¸âƒ£ Install Dependencies
pip install tensorflow opencv-python numpy matplotlib

3ï¸âƒ£ Run Emotion Recognition
jupyter notebook Emotion_Recognition.ipynb

4ï¸âƒ£ Run Finger Count Detection
jupyter notebook Fingercount.ipynb


ğŸ“¸ Emotion Recognition Demo
ğŸ“¸ Finger Count Detection Demo


ğŸ“Š Model Performance
Metric	Value
Training Accuracy	~90%
Validation Accuracy	~85%
Optimizer	Adam
Loss Function	Categorical Cross-Entropy
Epochs	10

(You can replace these values with your actual results.)


ğŸ§¾ Applications

Human-Computer Interaction

Emotion-Aware Systems

Virtual Assistants

Gaming Interfaces

Sign Language Recognition (extended use)

Mental Health Monitoring


ğŸ” Future Enhancements

Integrate both modules into a single unified GUI

Improve model accuracy using deeper CNN architectures

Add real-time emotion analytics dashboard

Integrate gesture and emotion input for hybrid control systems


ğŸ§‘â€ğŸ’» Author

Amita Sharma
ğŸ“ Major Project | Academic Submission
ğŸ“ India



â­ Acknowledgments

FER-2013 Dataset â€” for providing labeled facial expression data

TensorFlow/Keras â€” for deep learning framework support

OpenCV â€” for real-time computer vision and gesture detection

Matplotlib & NumPy â€” for visualization and numerical analysis
